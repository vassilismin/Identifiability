current_score <- global_optimum
# Create a 2-columns dataframe to store the tested theta_i values
# and the corresponding values of the objective function
backward_results_df <- data.frame(matrix(NA, nrow=N_samples, ncol = 2))
colnames(backward_results_df) <- c(theta_i_name, "Likelihood")
# take as constant_theta the parameter that will be fixed to a constant value
constant_theta <- thetas[i]
# Initiate theta_last and set it equal with the theta_hat
theta_last <- thetas
while (iter_counter < N_samples & current_score < threshold) {
iter_counter <- iter_counter + 1
# Estimation of theta_step
theta_step <-  nloptr::nloptr(x0 = 0.1,
eval_f = theta_step_estimation,
lb	= 1e-06,
ub = 1,
opts = opts_theta_step,
theta_last = theta_last, index = i,
global_optimum = global_optimum, q = q, Delta_alpha=Delta_alpha)$solution
# If theta_step exceeds the limits, take the value of the limit
if(theta_step > max_step_coef*constant_theta){
theta_step <- max_step_coef*constant_theta
}else if(theta_step < min_step_coef*constant_theta){
theta_step <- min_step_coef*constant_theta
}
# The parameter whose profile likelihood is examined
constant_theta <- constant_theta - theta_step
#Check if the constant_theta exceeded the corresponding lower boundary
if(constant_theta < lb[i]) break
# The name of the constant theta parameter
constant_theta_name <- theta_i_name
# Take as x0 all the parameters except the one which will be fixed
x0 <- theta_last[-i]
# The names of the rest parameters
params_names <- names(x0)
set.seed(12312)
optimization<- nloptr::nloptr(x0 = x0,
eval_f = updated_obj_func,
lb	= lb[-i],
ub = ub[-i],
opts = opts,
constant_theta = constant_theta,
constant_theta_name = constant_theta_name,
params_names = params_names,
PFAS_data = data_ls,
Cwater = Cwater,
age = age ,
temperatures = temperatures,
MW = MW,
weights_values = errors)
cat("Calculating PL for parameter ", theta_i_name, " and iter = ", iter_counter,". ", "step =", theta_step, ", ", constant_theta_name ," = ", constant_theta , "=> Likelihood = ", optimization$objective, "\n")
backward_results_df[iter_counter,] <- c(constant_theta, optimization$objective)
# update current score
current_score <- optimization$objective
#update theta_last vector with the new optimized values
for (k in 1:length(theta_last)) {
if(k==i){
theta_last[k] <- constant_theta
}else if(k>i){
theta_last[k] <- optimization$solution[k-1]
}else{
theta_last[k] <- optimization$solution[k]}
}
}
cat("Backward search ended after ", iter_counter, "iterations.", "\n")
results_df <- rbind(backward_results_df, forward_results_df, c(global_optimization$solution[i], global_optimization$objective))
results_df <- results_df[order(results_df[,1]),]
results_df <- results_df[complete.cases(results_df),]
sink()
return(results_df)
}
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(6,6,6,6, 5e-06)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(9,9, 9, 9, 1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.05)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(6,6,6,6, 5e-06)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(9,9, 9, 9, 1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.001)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(6,6,6,6, 5e-06)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(9,9, 9, 9, 1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.01)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(5,-1,1,5, 1e-07)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(12,10, 9, 12,  1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.01)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(5,-1,1,5, 1e-07)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(12,10, 9, 12,  1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.1)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.05)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
View(profile_likelihood)
#=======================#
#   Profile Likelihood  #
#=======================#
profile_likelihood <- function(X){
i=X$index # The index of the parameter whose PL is to be estimated
thetas=X$thetas # The optimal values of the parameters
thetas_names=X$thetas_names # the names of the parameters
lb=X$lb # The lower bounds of the parameters
ub=X$ub # The upper bounds of the parameters
N_samples=X$N_samples # The number of samples for each parameter
N_iter=X$N_iter # The maximum number of iterations of the optimizer
alpha = X$alpha # probability of chi-squared to estimate the quantile
df = X$df # the degrees of freedom of chi-squared to estimate the quantile
global_optimum = X$global_optimum # the minimum objective function value (equivalent to maximized likelihood value)
q = X$q # Parameter to estimate the theta_step
max_step_coef <- X$max_step_coef
min_step_coef <- X$min_step_coef
# Estimate the Delta_alpha parameter
Delta_alpha <- qchisq(alpha, df)
# Load the experimental data
data_ls <- openxlsx::read.xlsx ('C:/Users/vassi/Documents/GitHub/PFAS_biokinetics_models/D.Magna/Wang_2023/Wang_data_reduced2.xlsx', sheet = 'PFDoA')
data_plot <- openxlsx::read.xlsx ('C:/Users/vassi/Documents/GitHub/PFAS_biokinetics_models/D.Magna/Wang_2023/Wang_data.xlsx', sheet = 'PFDoA')
errors <- read.csv('C:/Users/vassi/Documents/GitHub/Identifiability/PFDoA_errors.csv')
# Convert water concentration in ng/L
Cwater = c(1.44, 2.05, 2.31)*1000
names(Cwater) <- c("16oC", "20oC", "24oC")
age = 7+7 # age of D.magna at the beginning of exposure in days
temperatures <- c(16, 20, 24) #experiment temperature in oC
MW <- 614 # molecular weight of PFDoA
theta_i_name <- names(thetas)[i] # the name of the theta_i parameter
# Function to estimate the theta_step by solving the equation
# chi^2(theta) - chi^2(theta_hat) - q*Delta_alpha = 0
theta_step_estimation <- function(theta_step, theta_last, index, global_optimum, q, Delta_alpha){
i <- index
x <- theta_last
x[i] <- x[i] + theta_step
chi2_last <- global_optimum
chi2 <- general_obj_func(x=x, data_ls, Cwater, age, temperatures,
MW, errors)
return(abs(chi2 - chi2_last - q*Delta_alpha))
}
# Set the threshold. The threshold is estimated as chi^2(theta_hat) + Delta_alpha
threshold =  global_optimum + Delta_alpha
sink(paste0("check_progress_",thetas_names[i], ".txt")) #keep a txt to check the progress while running
# Forward search
cat("Forward search begins...", "\n")
# Initiate a counter for the number of iterations
iter_counter <- 0
# Inititate a parameter to check if the threshold is exceeded in each iteration
current_score <- global_optimum
# Create a 2-columns dataframe to store the tested theta_i values
# and the corresponding values of the objective function
forward_results_df <- data.frame(matrix(NA, nrow=N_samples, ncol = 2))
colnames(forward_results_df) <- c(theta_i_name, "Likelihood")
# take as constant_theta the parameter that will be fixed to a constant value
constant_theta <- thetas[i]
# Initiate theta_last and set it equal with the theta_hat
theta_last <- thetas
# the selected settings for the optimizer
opts <- list( "algorithm" = "NLOPT_LN_NELDERMEAD", #"NLOPT_LN_SBPLX", #"NLOPT_LN_BOBYQA" #"NLOPT_LN_COBYLA"
"xtol_rel" = 1e-06,
"ftol_rel" = 1e-06,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = N_iter,
"print_level" = 0)
opts_theta_step <- list( "algorithm" = 'NLOPT_LN_BOBYQA', #"NLOPT_LN_NELDERMEAD", #"NLOPT_LN_SBPLX", #"NLOPT_LN_BOBYQA" #"NLOPT_LN_COBYLA"
"xtol_rel" = 1e-05,
"ftol_rel" = 1e-05,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 50,
"print_level" = 0)
while (iter_counter < N_samples & current_score < threshold) {
iter_counter <- iter_counter + 1
# Estimation of theta_step
theta_step <-  nloptr::nloptr(x0 = 0.1,
eval_f = theta_step_estimation,
lb	= 1e-06,
ub = 1,
opts = opts_theta_step,
theta_last = theta_last, index = i,
global_optimum = global_optimum, q = q, Delta_alpha=Delta_alpha)$solution
# If theta_step exceeds the limits, take the value of the limit
if(theta_step > max_step_coef*constant_theta){
theta_step <- max_step_coef*constant_theta
}else if(theta_step < min_step_coef*constant_theta){
theta_step <- min_step_coef*constant_theta
}
# The parameter whose profile likelihood is examined
constant_theta <- constant_theta + theta_step
#Check if the constant_theta exceeded the corresponding upper boundary
#if(constant_theta > ub[i]) break
# The name of the constant theta parameter
constant_theta_name <- theta_i_name
# Take as x0 all the parameters except the one which will be fixed
x0 <- theta_last[-i]
# The names of the rest parameters
params_names <- names(x0)
# define the lower and upper bounds of the parameters
set.seed(12312)
optimization<- nloptr::nloptr(x0 = x0,
eval_f = updated_obj_func,
lb	= lb[-i],
ub = ub[-i],
opts = opts,
constant_theta = constant_theta,
constant_theta_name = constant_theta_name,
params_names = params_names,
PFAS_data = data_ls,
Cwater = Cwater,
age = age ,
temperatures = temperatures,
MW = MW,
weights_values = errors)
cat("Calculating PL for parameter ", theta_i_name, " and iter = ", iter_counter,". ", "step =", theta_step , constant_theta_name ," = ", constant_theta , "=> Likelihood = ", optimization$objective, "\n")
forward_results_df[iter_counter,] <- c(constant_theta, optimization$objective)
# update current score
current_score <- optimization$objective
#update theta_last vector with the new optimized values
for (k in 1:length(theta_last)) {
if(k==i){
theta_last[k] <- constant_theta
}else if(k>i){
theta_last[k] <- optimization$solution[k-1]
}else{
theta_last[k] <- optimization$solution[k]}
}
}
cat("Forward search ended after ", iter_counter, "iterations.", "\n")
# Backward search
cat("Backward search begins...", "\n")
# Initiate a counter for the number of iterations
iter_counter <- 0
# Inititate a parameter to check if the threshold is exceeded in each iteration
current_score <- global_optimum
# Create a 2-columns dataframe to store the tested theta_i values
# and the corresponding values of the objective function
backward_results_df <- data.frame(matrix(NA, nrow=N_samples, ncol = 2))
colnames(backward_results_df) <- c(theta_i_name, "Likelihood")
# take as constant_theta the parameter that will be fixed to a constant value
constant_theta <- thetas[i]
# Initiate theta_last and set it equal with the theta_hat
theta_last <- thetas
while (iter_counter < N_samples & current_score < threshold) {
iter_counter <- iter_counter + 1
# Estimation of theta_step
theta_step <-  nloptr::nloptr(x0 = 0.1,
eval_f = theta_step_estimation,
lb	= 1e-06,
ub = 1,
opts = opts_theta_step,
theta_last = theta_last, index = i,
global_optimum = global_optimum, q = q, Delta_alpha=Delta_alpha)$solution
# If theta_step exceeds the limits, take the value of the limit
if(theta_step > max_step_coef*constant_theta){
theta_step <- max_step_coef*constant_theta
}else if(theta_step < min_step_coef*constant_theta){
theta_step <- min_step_coef*constant_theta
}
# The parameter whose profile likelihood is examined
constant_theta <- constant_theta - theta_step
#Check if the constant_theta exceeded the corresponding lower boundary
#if(constant_theta < lb[i]) break
# The name of the constant theta parameter
constant_theta_name <- theta_i_name
# Take as x0 all the parameters except the one which will be fixed
x0 <- theta_last[-i]
# The names of the rest parameters
params_names <- names(x0)
set.seed(12312)
optimization<- nloptr::nloptr(x0 = x0,
eval_f = updated_obj_func,
lb	= lb[-i],
ub = ub[-i],
opts = opts,
constant_theta = constant_theta,
constant_theta_name = constant_theta_name,
params_names = params_names,
PFAS_data = data_ls,
Cwater = Cwater,
age = age ,
temperatures = temperatures,
MW = MW,
weights_values = errors)
cat("Calculating PL for parameter ", theta_i_name, " and iter = ", iter_counter,". ", "step =", theta_step, ", ", constant_theta_name ," = ", constant_theta , "=> Likelihood = ", optimization$objective, "\n")
backward_results_df[iter_counter,] <- c(constant_theta, optimization$objective)
# update current score
current_score <- optimization$objective
#update theta_last vector with the new optimized values
for (k in 1:length(theta_last)) {
if(k==i){
theta_last[k] <- constant_theta
}else if(k>i){
theta_last[k] <- optimization$solution[k-1]
}else{
theta_last[k] <- optimization$solution[k]}
}
}
cat("Backward search ended after ", iter_counter, "iterations.", "\n")
results_df <- rbind(backward_results_df, forward_results_df, c(global_optimization$solution[i], global_optimization$objective))
results_df <- results_df[order(results_df[,1]),]
results_df <- results_df[complete.cases(results_df),]
sink()
return(results_df)
}
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(5,-1,1,5, 1e-07)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(12,10, 9, 12,  1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=250,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.05)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(5,-1,1,5, 1e-07)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(12,10, 9, 12,  1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=50, N_iter=300,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.05)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
total.duration
optimized_params <- global_optimization$solution
names(optimized_params) <- c('ku', 'kon', 'Ka', 'ke', 'C_prot_init')
thetas <- optimized_params
thetas_names <- names(optimized_params)
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(5,-1,1,5, 1e-07)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(12,10, 9, 12,  1e-03)
# prepare the input for parallel processing
X <- vector("list", 5)
for(i in 1:5){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
lb=lb, ub=ub, N_samples=25, N_iter=300,
alpha=0.95, df=5,
global_optimum = global_optimization$objective,
q = 0.5,
max_step_coef = 0.5,
min_step_coef = 0.05)
}
start.time <- Sys.time()
cluster <- makeCluster(5)
clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
"WSSR", "updated_obj_func","optimized_params", "global_optimization",
"general_obj_func"))
output <- parLapply(cluster, X, profile_likelihood)
