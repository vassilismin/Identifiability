global_optimum = X$global_optimum # the minimum objective function value (equivalent to maximized likelihood value)
q = X$q # Parameter to estimate the theta_step
max_step_coef <- X$max_step_coef
min_step_coef <- X$min_step_coef
break_at_bounds <- X$break_at_bounds
opts <- X$opts
opts_theta_step <- X$opts_theta_step
create_txt <- X$create_txt
# Estimate the Delta_alpha parameter
Delta_alpha <- qchisq(alpha, df)
theta_i_name <- names(thetas)[i] # the name of the theta_i parameter
# Function to estimate the theta_step by solving the equation
# chi^2(theta) - chi^2(theta_hat) - q*Delta_alpha = 0
theta_step_estimation <- function(theta_step, theta_last, obj_f, constant_params, index, global_optimum, q, Delta_alpha){
i <- index
x <- theta_last
x[i] <- x[i] + theta_step
chi2_last <- global_optimum
chi2 <- obj_f(x = x, constant_theta = NULL, constant_theta_name = NULL, params_names = names(x),
constant_params = constant_params,
PFAS_data = data_df, Cwater = Cwater, age = age, temperatures = temperatures,
MW = MW, weights_values = errors_df)
return(abs(chi2 - chi2_last - q*Delta_alpha))
}
# Set the threshold. The threshold is estimated as chi^2(theta_hat) + Delta_alpha
threshold =  global_optimum + Delta_alpha
if(create_txt) sink(paste0("check_progress_",thetas_names[i], ".txt")) #keep a txt to check the progress while running
# Forward search
cat("Forward search begins...", "\n")
# Initiate a counter for the number of iterations
iter_counter <- 0
# Inititate a parameter to check if the threshold is exceeded in each iteration
current_score <- global_optimum
# Create a 2-columns dataframe to store the tested theta_i values
# and the corresponding values of the objective function
forward_results_df <- data.frame(matrix(NA, nrow=N_samples, ncol = 2))
colnames(forward_results_df) <- c(theta_i_name, "Likelihood")
# take as constant_theta the parameter that will be fixed to a constant value
constant_theta <- thetas[i]
# Initiate theta_last and set it equal with the theta_hat
theta_last <- thetas
while (iter_counter < N_samples & current_score < threshold) {
iter_counter <- iter_counter + 1
# Estimation of theta_step
theta_step <-  nloptr::nloptr(x0 = 0.1,
eval_f = theta_step_estimation,
lb	= 1e-06,
ub = 1,
opts = opts_theta_step,
theta_last = theta_last, index = i,
global_optimum = global_optimum, q = q, Delta_alpha=Delta_alpha,
obj_f=obj_f,
constant_params=constant_params)$solution
# If theta_step exceeds the limits, take the value of the limit
if(theta_step > max_step_coef*abs(constant_theta)){
theta_step <- max_step_coef*abs(constant_theta)
}else if(theta_step < min_step_coef*abs(constant_theta)){
theta_step <- min_step_coef*abs(constant_theta)
}
# The parameter whose profile likelihood is examined
constant_theta <- constant_theta + theta_step
#Check if the constant_theta exceeded the corresponding upper boundary
#if(constant_theta > ub[i]) break
# The name of the constant theta parameter
constant_theta_name <- theta_i_name
# Take as x0 all the parameters except the one which will be fixed
x0 <- theta_last[-i]
# The names of the rest parameters
params_names <- names(x0)
# define the lower and upper bounds of the parameters
set.seed(12312)
optimization<- nloptr::nloptr(x0 = x0,
eval_f = obj_f,
lb	= lb[-i],
ub = ub[-i],
opts = opts,
constant_theta = constant_theta,
constant_theta_name = constant_theta_name,
params_names = params_names,
constant_params=constant_params,
PFAS_data = data_df,
Cwater = Cwater,
age = age ,
temperatures = temperatures,
MW = MW,
weights_values = errors_df)
cat("Calculating PL for parameter ", theta_i_name, " and iter = ", iter_counter,". ", "step =", theta_step , constant_theta_name ," = ", constant_theta , "=> Likelihood = ", optimization$objective, "\n")
forward_results_df[iter_counter,] <- c(constant_theta, optimization$objective)
# update current score
current_score <- optimization$objective
#update theta_last vector with the new optimized values
for (k in 1:length(theta_last)) {
if(k==i){
theta_last[k] <- constant_theta
}else if(k>i){
theta_last[k] <- optimization$solution[k-1]
}else{
theta_last[k] <- optimization$solution[k]}
}
}
cat("Forward search ended after ", iter_counter, "iterations.", "\n")
# Backward search
cat("Backward search begins...", "\n")
# Initiate a counter for the number of iterations
iter_counter <- 0
# Inititate a parameter to check if the threshold is exceeded in each iteration
current_score <- global_optimum
# Create a 2-columns dataframe to store the tested theta_i values
# and the corresponding values of the objective function
backward_results_df <- data.frame(matrix(NA, nrow=N_samples, ncol = 2))
colnames(backward_results_df) <- c(theta_i_name, "Likelihood")
# take as constant_theta the parameter that will be fixed to a constant value
constant_theta <- thetas[i]
# Initiate theta_last and set it equal with the theta_hat
theta_last <- thetas
while (iter_counter < N_samples & current_score < threshold) {
iter_counter <- iter_counter + 1
# Estimation of theta_step
theta_step <-  nloptr::nloptr(x0 = 0.1,
eval_f = theta_step_estimation,
lb	= 1e-06,
ub = 1,
opts = opts_theta_step,
theta_last = theta_last, index = i,
global_optimum = global_optimum, q = q, Delta_alpha=Delta_alpha,
obj_f=obj_f,
constant_params=constant_params)$solution
# If theta_step exceeds the limits, take the value of the limit
if(theta_step > max_step_coef*abs(constant_theta)){
theta_step <- max_step_coef*abs(constant_theta)
}else if(theta_step < min_step_coef*abs(constant_theta)){
theta_step <- min_step_coef*abs(constant_theta)
}
# The parameter whose profile likelihood is examined
constant_theta <- constant_theta - theta_step
#Check if the constant_theta exceeded the corresponding lower boundary
#if(constant_theta < lb[i]) break
# The name of the constant theta parameter
constant_theta_name <- theta_i_name
# Take as x0 all the parameters except the one which will be fixed
x0 <- theta_last[-i]
# The names of the rest parameters
params_names <- names(x0)
set.seed(12312)
optimization<- nloptr::nloptr(x0 = x0,
eval_f = obj_f,
lb	= lb[-i],
ub = ub[-i],
opts = opts,
constant_theta = constant_theta,
constant_theta_name = constant_theta_name,
params_names = params_names,
constant_params=constant_params,
PFAS_data = data_df,
Cwater = Cwater,
age = age ,
temperatures = temperatures,
MW = MW,
weights_values = errors_df)
cat("Calculating PL for parameter ", theta_i_name, " and iter = ", iter_counter,". ", "step =", theta_step , constant_theta_name ," = ", constant_theta , "=> Likelihood = ", optimization$objective, "\n")
backward_results_df[iter_counter,] <- c(constant_theta, optimization$objective)
# update current score
current_score <- optimization$objective
#update theta_last vector with the new optimized values
for (k in 1:length(theta_last)) {
if(k==i){
theta_last[k] <- constant_theta
}else if(k>i){
theta_last[k] <- optimization$solution[k-1]
}else{
theta_last[k] <- optimization$solution[k]}
}
}
cat("Backward search ended after ", iter_counter, "iterations.", "\n")
results_df <- rbind(backward_results_df, forward_results_df, c(thetas[i], global_optimum))
results_df <- results_df[order(results_df[,1]),]
results_df <- results_df[complete.cases(results_df),]
if(create_txt) sink()
return(results_df)
}
Identifiability_analysis <- function(obj_f, thetas, thetas_names, data_df, errors_df,
lb, ub,
N_samples = 250,
alpha = 0.95, df = 1,
q = 0.5,
global_optimum,
min_step_coef = 1e-03, max_step_coef = 0.2,
N_cores,
constant_params = NULL,
exported_to_cluster = NULL,
break_at_bounds = FALSE,
# nlopt settings for the main optimization problem
opts = list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 1e-06,
"ftol_rel" = 1e-06,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 300,
"print_level" = 0),
# nlopt settings for the estimation of theta_step
opts_theta_step = list("algorithm" = 'NLOPT_LN_SBPLX',
"xtol_rel_step" = 1e-05,
"ftol_rel_step" = 1e-05,
"ftol_abs_step" = 0.0,
"xtol_abs_step" = 0.0 ,
"maxeval_step" = 50,
"print_level_step" = 0),
create_txt = TRUE){
# Number of parameters tested in the identifiability analysis
N_parameters <- length(thetas)
# prepare the input for parallel processing
X <- vector("list", N_parameters)
for(i in 1:N_parameters){
X[[i]] <- list(index=i, thetas=thetas, thetas_names=thetas_names,
constant_params = constant_params,
data_df = data_df,
errors_df = errors_df,
lb=lb, ub=ub, N_samples=N_samples,
alpha=alpha, df=df,
global_optimum = global_optimum,
q = q,
max_step_coef = max_step_coef,
min_step_coef = min_step_coef,
break_at_bounds = FALSE,
opts = opts,
opts_theta_step=opts_theta_step,
create_txt = create_txt)
}
start.time <- Sys.time()
cluster <- makeCluster(N_cores)
# Export to the cluster any function or parameter that the obj_f needs to work.
# clusterExport(cl=cluster, c("Size_estimation","dry_weight_estimation", "ode_func",
#                             "WSSR", "updated_obj_func","optimized_params"))
clusterExport(cl=cluster, c(names(exported_to_cluster),"obj_f"))
output <- parLapply(cluster, X, profile_likelihood)
stopCluster(cluster)
total.duration <- Sys.time() - start.time
print(total.duration)
return(list("output" = output, "Total_duration" = total.duration))
}
#####
# Extra input needed to be parsed to profile_likelihood (problem-specific parameters and data)
# Load the experimental data
data_ls <- openxlsx::read.xlsx ('C:/Users/vassi/Documents/GitHub/PFAS_biokinetics_models/D.Magna/Wang_2023/Wang_data_reduced2.xlsx', sheet = 'PFDoA')
errors_df <- read.csv('C:/Users/vassi/Documents/GitHub/Identifiability/Daphnia_magna_example/PFDoA_errors.csv')
# Convert water concentration in ng/L
Cwater = c(1.44, 2.05, 2.31)*1000
names(Cwater) <- c("16oC", "20oC", "24oC")
age = 7+7 # age of D.magna at the beginning of exposure in days
temperatures <- c(16, 20, 24) #experiment temperature in oC
MW <- 614 # molecular weight of PFDoA
# lower bounds of parameters
#lb <- c(4, 4, 5, 6, 1e-06)
lb <- c(3,3,3)
# upper bounds of parameters
#ub <- c(8, 9, 8.5, 8.5, 1e-04)
ub <- c(10,10,10)
constant_params <- c("Ka"=7.681146, "C_prot_init" = -4.189729)
exported_to_cluster = list("Size_estimation"=Size_estimation,
"dry_weight_estimation"=dry_weight_estimation,
"ode_func"=ode_func,
"WSSR"=WSSR,
"age"=age,
"Cwater"=Cwater,
"temperatures"=temperatures,
"MW"=MW)
thetas <- c(7.264904, 6.94284, 7.728766)
thetas_names <- c("ku", "kon", "ke")
names(thetas) <- thetas_names
global_optimum <- 6.54365835275129
test <- Identifiability_analysis(obj_f = obj_f,
thetas=thetas,
thetas_names=thetas_names,
data_df=data_ls ,
errors_df=errors_df,
lb=lb ,
ub=ub,
N_samples = 5,
alpha = 0.95 ,
df = 1,
q = 0.5,
global_optimum = global_optimum ,
min_step_coef = 1e-03 ,
max_step_coef = 0.2,
N_cores = 3,
constant_params = constant_params,
exported_to_cluster = exported_to_cluster,
break_at_bounds = FALSE,
# nlopt settings for the main optimization problem
opts = list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 1e-06,
"ftol_rel" = 1e-06,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 250,
"print_level" = 0),
# nlopt settings for the estimation of theta_step
opts_theta_step = list("algorithm" = 'NLOPT_LN_SBPLX',
"xtol_rel" = 1e-05 ,
"ftol_rel" = 1e-05,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 50,
"print_level" = 0),
create_txt = TRUE)
test <- Identifiability_analysis(obj_f = obj_f,
thetas=thetas,
thetas_names=thetas_names,
data_df=data_ls ,
errors_df=errors_df,
lb=lb ,
ub=ub,
N_samples = 25,
alpha = 0.95 ,
df = 1,
q = 0.5,
global_optimum = global_optimum ,
min_step_coef = 1e-03 ,
max_step_coef = 0.2,
N_cores = 3,
constant_params = constant_params,
exported_to_cluster = exported_to_cluster,
break_at_bounds = FALSE,
# nlopt settings for the main optimization problem
opts = list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 1e-06,
"ftol_rel" = 1e-06,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 300,
"print_level" = 0),
# nlopt settings for the estimation of theta_step
opts_theta_step = list("algorithm" = 'NLOPT_LN_SBPLX',
"xtol_rel" = 1e-05 ,
"ftol_rel" = 1e-05,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 50,
"print_level" = 0),
create_txt = TRUE)
output <- test$output
plot_list <- list()
alpha <- 0.95
df <- 1
for (i in 1:length(output)) {
data_to_plot <- output[[i]]
current_param <- names(data_to_plot)[1]
names(data_to_plot)[1] <- "Parameter"
optimal_value <- data.frame(global_optimization$solution[i], global_optimization$objective)
names(optimal_value) <- c("Parameter", "Likelihood")
plot <- ggplot()+
geom_hline(yintercept=global_optimization$objective + qchisq(alpha,df), linetype="dashed", color = "red", size=1)+
#geom_hline(yintercept=global_optimization$objective + qchisq(0.95,1), linetype="dashed", color = "green", size=1)+
geom_hline(yintercept=global_optimization$objective , linetype="dashed", color = "blue", size=1)+
geom_line(data = data_to_plot,  aes(x=Parameter, y=Likelihood), color = 'black', size=2)+
#geom_smooth(data = data_to_plot,  aes(x=Parameter, y=Likelihood), method = "loess", span = 0.5, se =0, color = 'black', size=2)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=11)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, colour="pink", size=10)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=5)+
#scale_y_log10()+
ylim(c(5,NA))+
labs(title = paste0("Profile Likelihood of ", current_param),
y = expression(paste(chi^2, "(", theta, ")")) , x = current_param)+
theme(plot.title = element_text(hjust = 0.5,size=30),
axis.title.y =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.y=element_text(size=22),
axis.title.x =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.x=element_text(size=22),
legend.title=element_text(hjust = 0.5,size=25),
legend.text=element_text(size=22),
panel.border = element_rect(colour = "black", fill=NA, size=1.0))
#print(plot)
plot_list[[i]] <- plot
}
for (i in 1:length(output)) {
data_to_plot <- output[[i]]
current_param <- names(data_to_plot)[1]
names(data_to_plot)[1] <- "Parameter"
optimal_value <- data.frame(global_optimization$solution[i], global_optimization$objective)
names(optimal_value) <- c("Parameter", "Likelihood")
plot <- ggplot()+
geom_hline(yintercept=global_optimum + qchisq(alpha,df), linetype="dashed", color = "red", size=1)+
#geom_hline(yintercept=global_optimization$objective + qchisq(0.95,1), linetype="dashed", color = "green", size=1)+
geom_hline(yintercept=global_optimum , linetype="dashed", color = "blue", size=1)+
geom_line(data = data_to_plot,  aes(x=Parameter, y=Likelihood), color = 'black', size=2)+
#geom_smooth(data = data_to_plot,  aes(x=Parameter, y=Likelihood), method = "loess", span = 0.5, se =0, color = 'black', size=2)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=11)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, colour="pink", size=10)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=5)+
#scale_y_log10()+
ylim(c(5,NA))+
labs(title = paste0("Profile Likelihood of ", current_param),
y = expression(paste(chi^2, "(", theta, ")")) , x = current_param)+
theme(plot.title = element_text(hjust = 0.5,size=30),
axis.title.y =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.y=element_text(size=22),
axis.title.x =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.x=element_text(size=22),
legend.title=element_text(hjust = 0.5,size=25),
legend.text=element_text(size=22),
panel.border = element_rect(colour = "black", fill=NA, size=1.0))
#print(plot)
plot_list[[i]] <- plot
}
output <- test$output
plot_list <- list()
alpha <- 0.95
df <- 1
for (i in 1:length(output)) {
data_to_plot <- output[[i]]
current_param <- names(data_to_plot)[1]
names(data_to_plot)[1] <- "Parameter"
optimal_value <- data.frame(thetas[i], global_optimum)
names(optimal_value) <- c("Parameter", "Likelihood")
plot <- ggplot()+
geom_hline(yintercept=global_optimum + qchisq(alpha,df), linetype="dashed", color = "red", size=1)+
#geom_hline(yintercept=global_optimization$objective + qchisq(0.95,1), linetype="dashed", color = "green", size=1)+
geom_hline(yintercept=global_optimum , linetype="dashed", color = "blue", size=1)+
geom_line(data = data_to_plot,  aes(x=Parameter, y=Likelihood), color = 'black', size=2)+
#geom_smooth(data = data_to_plot,  aes(x=Parameter, y=Likelihood), method = "loess", span = 0.5, se =0, color = 'black', size=2)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=11)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, colour="pink", size=10)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=5)+
#scale_y_log10()+
ylim(c(5,NA))+
labs(title = paste0("Profile Likelihood of ", current_param),
y = expression(paste(chi^2, "(", theta, ")")) , x = current_param)+
theme(plot.title = element_text(hjust = 0.5,size=30),
axis.title.y =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.y=element_text(size=22),
axis.title.x =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.x=element_text(size=22),
legend.title=element_text(hjust = 0.5,size=25),
legend.text=element_text(size=22),
panel.border = element_rect(colour = "black", fill=NA, size=1.0))
#print(plot)
plot_list[[i]] <- plot
}
# Arrange and print the plots in a grid
grid.arrange(grobs = plot_list, nrow = 1)
test <- Identifiability_analysis(obj_f = obj_f,
thetas=thetas,
thetas_names=thetas_names,
data_df=data_ls ,
errors_df=errors_df,
lb=lb ,
ub=ub,
N_samples = 50,
alpha = 0.95 ,
df = 1,
q = 0.5,
global_optimum = global_optimum ,
min_step_coef = 1e-03 ,
max_step_coef = 0.2,
N_cores = 3,
constant_params = constant_params,
exported_to_cluster = exported_to_cluster,
break_at_bounds = FALSE,
# nlopt settings for the main optimization problem
opts = list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 1e-06,
"ftol_rel" = 1e-06,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 300,
"print_level" = 0),
# nlopt settings for the estimation of theta_step
opts_theta_step = list("algorithm" = 'NLOPT_LN_SBPLX',
"xtol_rel" = 1e-05 ,
"ftol_rel" = 1e-05,
"ftol_abs" = 0.0,
"xtol_abs" = 0.0 ,
"maxeval" = 50,
"print_level" = 0),
create_txt = TRUE)
output <- test$output
plot_list <- list()
alpha <- 0.95
df <- 1
for (i in 1:length(output)) {
data_to_plot <- output[[i]]
current_param <- names(data_to_plot)[1]
names(data_to_plot)[1] <- "Parameter"
optimal_value <- data.frame(thetas[i], global_optimum)
names(optimal_value) <- c("Parameter", "Likelihood")
plot <- ggplot()+
geom_hline(yintercept=global_optimum + qchisq(alpha,df), linetype="dashed", color = "red", size=1)+
#geom_hline(yintercept=global_optimization$objective + qchisq(0.95,1), linetype="dashed", color = "green", size=1)+
geom_hline(yintercept=global_optimum , linetype="dashed", color = "blue", size=1)+
geom_line(data = data_to_plot,  aes(x=Parameter, y=Likelihood), color = 'black', size=2)+
#geom_smooth(data = data_to_plot,  aes(x=Parameter, y=Likelihood), method = "loess", span = 0.5, se =0, color = 'black', size=2)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=11)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, colour="pink", size=10)+
geom_point(data = optimal_value,  aes(x=Parameter, y=Likelihood), shape=18, size=5)+
#scale_y_log10()+
ylim(c(5,NA))+
labs(title = paste0("Profile Likelihood of ", current_param),
y = expression(paste(chi^2, "(", theta, ")")) , x = current_param)+
theme(plot.title = element_text(hjust = 0.5,size=30),
axis.title.y =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.y=element_text(size=22),
axis.title.x =element_text(hjust = 0.5,size=25,face="bold"),
axis.text.x=element_text(size=22),
legend.title=element_text(hjust = 0.5,size=25),
legend.text=element_text(size=22),
panel.border = element_rect(colour = "black", fill=NA, size=1.0))
#print(plot)
plot_list[[i]] <- plot
}
# Arrange and print the plots in a grid
grid.arrange(grobs = plot_list, nrow = 1)
save.image("C:/Users/vassi/Documents/GitHub/Identifiability/Daphnia_magna_example/ku_kon_ke_problem 2.RData")
